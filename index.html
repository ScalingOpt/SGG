<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Taming LLMs by Scaling Learning Rates with Gradient Grouping</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: "Times New Roman", Times, serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background: linear-gradient(135deg, #007bff, #0056b3);
            color: white;
            padding: 4rem 0;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        nav {
            background: #343a40;
            padding: 1rem 0;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        nav ul {
            list-style: none;
            display: flex;
            justify-content: center;
            gap: 2rem;
        }

        nav a {
            color: white;
            text-decoration: none;
            font-size: 1.1rem;
            transition: color 0.3s;
        }

        nav a:hover {
            color: #007bff;
        }

        section {
            padding: 3rem 0;
        }

        section h2 {
            font-size: 2rem;
            color: #343a40;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        section p, section ul {
            font-size: 1.1rem;
            margin-bottom: 1rem;
        }

        ul {
            list-style: disc;
            margin-left: 2rem;
        }

        .buttons {
            display: flex;
            justify-content: center;
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .button {
            display: flex;
            align-items: center;
            padding: 0.8rem 1.5rem;
            background: #007bff;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            transition: background 0.3s, transform 0.2s;
            font-size: 1rem;
        }

        .button img {
            width: 24px;
            height: 24px;
            margin-right: 0.5rem;
        }

        .button:hover {
            background: #0056b3;
            transform: translateY(-2px);
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            background: white;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        th, td {
            padding: 0.8rem;
            border: 1px solid #dee2e6;
            text-align: center;
            font-size: 1rem;
        }

        th {
            background: #343a40;
            color: white;
        }

        tr:nth-child(even) {
            background: #f8f9fa;
        }

        footer {
            background: #343a40;
            color: white;
            text-align: center;
            padding: 1rem 0;
            margin-top: 2rem;
        }

        @media (max-width: 768px) {
            header h1 {
                font-size: 1.8rem;
            }

            nav ul {
                flex-direction: column;
                text-align: center;
                gap: 1rem;
            }

            table {
                font-size: 0.9rem;
            }

            th, td {
                padding: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Taming LLMs by Scaling Learning Rates with Gradient Grouping</h1>
            <p>Siyuan Li<sup>1</sup>, Juanxi Tian<sup>1</sup>, Zedong Wang<sup>2</sup>, Xin Jin<sup>3</sup>, Zicheng Liu<sup>4,5,*</sup>, Wentao Zhang<sup>2</sup>, Dan Xu<sup>5</sup><br>
            <sup>1</sup>Zhejiang University, <sup>2</sup>Peking University, <sup>3</sup>Westlake University, <sup>4</sup>Westlake University, <sup>5</sup>The Hong Kong University of Science and Technology<br>
            *Corresponding author</p>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="#abstract">Abstract</a></li>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#methodology">Methodology</a></li>
            <li><a href="#results">Results</a></li>
            <li><a href="#links">Links</a></li>
        </ul>
    </nav>

    <section id="abstract">
        <div class="container">
            <h2>Abstract</h2>
            <p>Training large language models (LLMs) poses challenges due to their massive scale and heterogeneous architectures. While adaptive optimizers like AdamW help address gradient variations, they still struggle with efficient and effective parameter-wise learning rate estimation, resulting in training instability, slow convergence, and poor compatibility with parameter-efficient fine-tuning (PEFT) techniques. This work introduces Scaling with Gradient Grouping (SGG), an optimizer wrapper that improves adaptive learning rate estimation by dynamic grouping and group-specific scaling. SGG first groups gradient statistics in each layer into clusters and then applies cluster-specific scaling to calibrate learning rates for each parameter, thus imposing collective group-wise constraints while maintaining precise per-parameter adaptation. Experiments on diverse (M)LLM benchmarks show that SGG integrates seamlessly with existing optimizers, offering consistent gains and faster convergence over baselines across various model sizes. Its stability across varying batch sizes and learning rates establishes SGG as a robust choice for LLM optimization.</p>
        </div>
    </section>

    <section id="overview">
        <div class="container">
            <h2>Overview & Key Takeaways</h2>
            <p>Training large language models (LLMs) presents significant challenges due to their scale and architectural heterogeneity. Adaptive optimizers like AdamW help but still face issues with training instability and slow convergence, especially when combined with parameter-efficient fine-tuning (PEFT) techniques. This paper introduces Scaling with Gradient Grouping (SGG), an optimizer wrapper that enhances adaptive learning rate estimation by dynamically grouping gradient statistics and applying cluster-specific scaling. SGG improves training stability, convergence speed, and compatibility with PEFT, as demonstrated through experiments on various LLM and MLLM benchmarks.</p>
            <h3>Key Takeaways</h3>
            <ul>
                <li>SGG enhances adaptive learning rate estimation through dynamic gradient grouping and cluster-specific scaling.</li>
                <li>It offers consistent performance gains across diverse (M)LLM benchmarks and model sizes.</li>
                <li>SGG is robust to varying batch sizes and learning rates, ensuring stable training.</li>
                <li>It integrates seamlessly with existing optimizers and PEFT techniques, improving convergence speed.</li>
            </ul>
        </div>
    </section>

    <section id="methodology">
        <div class="container">
            <h2>Methodology</h2>
            <p>SGG enhances adaptive learning rate estimation by dynamically grouping gradient statistics and applying cluster-specific scaling. It uses online clustering to group parameters based on their gradient statistics, reducing memory overhead while maintaining per-parameter adaptation. The learning rates are then scaled based on the median deviation of each cluster from the global average, ensuring balanced optimization across different parameter groups.</p>
        </div>
    </section>

    <section id="results">
        <div class="container">
            <h2>Experimental Results</h2>
            <h3>Table 1: Overview of Optimizers</h3>
            <table>
                <thead>
                    <tr>
                        <th>Category</th>
                        <th>Method</th>
                        <th>Adaptive LR</th>
                        <th>Basic State</th>
                        <th>Extra State</th>
                        <th>Low-Rank Plugin</th>
                        <th>Extra Branch</th>
                        <th>C4 ↓</th>
                        <th>GPU Memory</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Classical Opt.</td>
                        <td>SGD</td>
                        <td>✗</td>
                        <td>Weight & Grad.</td>
                        <td>✗</td>
                        <td>✗</td>
                        <td>✗</td>
                        <td>−</td>
                        <td>2mn</td>
                    </tr>
                    <tr>
                        <td rowspan="2">Adaptive Opt.</td>
                        <td>Adam</td>
                        <td>✓</td>
                        <td>Weight & Grad.</td>
                        <td>Momentum & Variance</td>
                        <td>✗</td>
                        <td>✗</td>
                        <td>23.36</td>
                        <td>3mn</td>
                    </tr>
                    <tr>
                        <td>Adafactor</td>
                        <td>✓</td>
                        <td>Weight & Grad.</td>
                        <td>Factored Momentum</td>
                        <td>✗</td>
                        <td>✗</td>
                        <td>−</td>
                        <td>2mn+(m+n)</td>
                    </tr>
                    <tr>
                        <td>PEFT Opt.</td>
                        <td>CAME</td>
                        <td>✓</td>
                        <td>Weight & Grad.</td>
                        <td>Low-rank Momentum</td>
                        <td>✓</td>
                        <td>✓</td>
                        <td>-1.64</td>
                        <td>2mn+2(m+n)</td>
                    </tr>
                    <tr>
                        <td>Wrapper</td>
                        <td>SGG</td>
                        <td>✓</td>
                        <td>−</td>
                        <td>−</td>
                        <td>✓</td>
                        <td>−</td>
                        <td>-1.99</td>
                        <td>+0</td>
                    </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 1 compares adaptive learning rate costs, low-rank integration, and performance for C4 pre-training. SGG achieves a PPL reduction of -1.99 with no additional GPU memory cost.</em></p>

            <h3>Table 2: Group Statistics for SGG Scaling</h3>
            <table>
                <thead>
                    <tr>
                        <th>Statistics</th>
                        <th>130M</th>
                        <th>350M</th>
                        <th>1B</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Param</td>
                        <td>25.08</td>
                        <td>17.92</td>
                        <td>15.56</td>
                    </tr>
                    <tr>
                        <td>Mean</td>
                        <td>22.76</td>
                        <td>17.47</td>
                        <td>14.76</td>
                    </tr>
                    <tr>
                        <td>MAD</td>
                        <td>22.58</td>
                        <td>17.37</td>
                        <td>14.54</td>
                    </tr>
                    <tr>
                        <td>MDA</td>
                        <td>22.18</td>
                        <td>17.28</td>
                        <td>14.30</td>
                    </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 2 shows validation PPL for LLaMA on C4 using different statistics. MDA yields the best results across all model sizes.</em></p>

            <h3>Table 2: Gains vs. Costs</h3>
            <table>
                <tr>
                    <th>Mode</th>
                    <th>PPL</th>
                    <th>Time (+h)</th>
                    <th>GPU Memory</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>GPU</td>
                    <td>6.5</td>
                    <td>2</td>
                    <td>4.3G</td>
                </tr>
                <tr>
                    <td>CPU</td>
                    <td>6.35</td>
                    <td>9</td>
                    <td>0.0G</td>
                </tr>
                <tr>
                    <td>Hybrid</td>
                    <td>6.35</td>
                    <td>4</td>
                    <td>2.1G</td>
                </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 3 evaluates relative PPL gains and costs for LLaMA-1B on C4. SGG achieves a 6.5% PPL gain with minimal overhead in Hybrid mode.</em></p>

            <h3>Table 4: C4 Pre-training with LLaMA</h3>
            <table>
                <thead>
                    <tr>
                        <th>Optimizer</th>
                        <th>60M</th>
                        <th>130M</th>
                        <th>350M</th>
                        <th>1B</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>AdamW</td>
                        <td>34.68</td>
                        <td>32.48</td>
                        <td>25.00</td>
                        <td>18.78</td>
                    </tr>
                    <tr>
                        <td>Adam+SGG</td>
                        <td>30.31</td>
                        <td>22.18</td>
                        <td>17.28</td>
                        <td>14.30</td>
                    </tr>
                    <tr>
                        <td>LoRA</td>
                        <td>−4.37</td>
                        <td>−10.30</td>
                        <td>−7.72</td>
                        <td>−4.48</td>
                    </tr>
                </tbody>
            </table>
            </table>
            <p><em>Annotation: Table 4 compares PPLs for LLaMA models. Adam+SGG consistently outperforms, with LoRA+SGG showing significant gains.</em></p>

            <h3>Table 5: GLUE Benchmark with RoBERTa</h3>
            <table>
                <thead>
                    <tr>
                        <th>Optimizer</th>
                        <th>Full-Rank</th>
                        <th>Rank 4</th>
                        <th>Rank 8</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>AdamW</td>
                        <td>−</td>
                        <td>−</td>
                        <td>−</td>
                    </tr>
                    <tr>
                        <td>AdamW+SGG</td>
                        <td>+1.00</td>
                        <td>+1.27</td>
                        <td>+0.92</td>
                    </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 5 reports top-1 accuracy gains on GLUE with RoBERTa. SGG improves performance across all settings.</em></p>

            <h3>Table 6: LLaMA-7B PEFT on Commonsense</h3>
            <table>
                <thead>
                    <tr>
                        <th>Optimizer</th>
                        <th>BoolQ</th>
                        <th>PIQA</th>
                        <th>OBQA</th>
                        <th>Avg</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>LoRA</td>
                        <td>−</td>
                        <td>
                        <td>−</td>
                        <td>−</td>
                    </tr>
                    <tr>
                        <td>LoRA+SGG</td>
                        <td>+1.4</td>
                        <td>+2.9</td>
                        <td>+4.2</td>
                        <td>+2.9</td>
                    </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 6 shows LoRA+SGG improving commonsense reasoning tasks with an average accuracy gain of +2.9%.</em></p>

            <h3>Table 7: Qwen2.5-0.5B DPO Results</h3>
            <table>
                <thead>
                    <tr>
                        <th>Optimizer</th>
                        <th>Full-rank</th>
                        <th>LoRA</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>AdamW t<td>
                        <td>71.39</td>
                        <td>70.22</td>
                    </tr>
                    <tr>
                        <td>AdamW+SGG</td>
                        <td>71.84</td>
                        <td>72.02</td>
                    </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 7 compares DPO accuracy. SGG+SGG enhances LoRA performance with a +1.80% gain.</em></p>

            <h3>Table 8: MLLM Performance</h3>
            <table>
                <thead>
                    <tr>
                        <th>Optimizer</th>
                        <th>VizWiz</th>
                        <th>Average</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>AdamW</td>
                        <td>−</td>
                        <td>−</td>
                    </tr>
                    <tr>
                        <td>AdamW+SGG</td>
                        <td>+1.0</td>
                        <td>+1.0</td>
                    </tr>
                    <tr>
                        <td>Adafactor+SGG</td>
                        <td>+2.4</td>
                        <td>+0.6</td>
                    </tr>
                </tbody>
            </table>
            </table>
            <p><em>Annotation: Table 8 shows SGG improving MLLM performance, with notable gains on VizWiz (+2.4%).</em></p>

            <h3>Table 9: Ablation Studies</h3>
            <table>
                <thead>
                    <tr>
                        <th>Task</th>
                        <th>K=1</th>
                        <th>K=2</th>
                        <th>K=3</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>LLaMA-60M</td>
                        <td>34.1</td>
                        <td>30.3</td>
                        <td>30.8</td>
                    </tr>
                    <tr>
                        <td>LLaMA-130M</td>
                        <td>25.1</td>
                        <td>23.3</td>
                        <td>23.5</td>
                    </tr>
                </tbody>
            </table>
            <p><em>Annotation: Table 9 ablates the number of SGG clusters, showing optimal results at K=2 for most tasks.</em></p>
        </div>
    </section>

    <section id="links">
        <div class="container">
            <h2>Links</h2>
            <div class="buttons">
                <a href="https://arxiv.org/pdf/2506.01049" target="_blank" class="button">
                    <img src="https://arxiv.org/icons/sfx.gif" alt="arXiv Logo">
                    Paper
                </a>
                <a href="https://github.com/ScalingOpt/SGG" target="_blank" class="button">
                    <img src="https://github.githubassets.com/images/modules/logos_page/Octocat.png" alt="GitHub Logo">
                    Code
                </a>
            </div>
            <h3>Citation</h3>
            <pre>
@article{Li2025,
  author  = {Li, Siyuan and Tian, Juanxi and Wang, Zedong and Jin, Xin and Liu, Zicheng and Zhang, Wentao and Xu, Dan},
  title   = {Taming LLMs by Scaling Learning Rates with Gradient Grouping with Grouping},
  journal = {arXiv:},
  year    = {2025}
}
            </pre>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 SGG Project Team. All Rights Reserved.</p>
    </footer>
</body>
</html>