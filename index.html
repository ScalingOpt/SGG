<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Taming LLMs by Scaling Learning Rates with Gradient Grouping</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        body {
            font-family: 'Times New Roman', serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
            color: #333;
        }
        .header {
            background-color: #333;
            color: #fff;
            padding: 10px 0;
            text-align: center;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        .title {
            font-size: 36px;
            font-weight: bold;
            text-align: center;
            margin-bottom: 20px;
        }
        .authors {
            text-align: center;
            margin-bottom: 30px;
        }
        .authors span {
            font-weight: bold;
        }
        .buttons {
            text-align: center;
            margin-bottom: 50px;
        }
        .buttons a {
            display: inline-block;
            margin: 0 10px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            color: #fff;
            font-size: 18px;
            text-decoration: none;
            transition: background-color 0.3s;
        }
        .buttons a:hover {
            opacity: 0.8;
        }
        .buttons a#paper-btn {
            background-color: #2ca02c;
        }
        .buttons a#code-btn {
            background-color: #2274a5;
        }
        .content {
            background-color: #fff;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .content h2 {
            font-size: 28px;
            font-weight: bold;
            margin-bottom: 20px;
        }
        .content p {
            font-size: 18px;
            line-height: 1.5;
            margin-bottom: 20px;
        }
        .content img {
            max-width: 100%;
            height: auto;
            margin-bottom: 20px;
        }
        .content table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        .content th, .content td {
            padding: 10px;
            text-align: left;
        }
        .content th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        .content td {
            font-family: 'Arial', sans-serif;
        }
        .footer {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 10px 0;
            margin-top: 50px;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Taming LLMs by Scaling Learning Rates with Gradient Grouping</h1>
    </div>
    <div class="container">
        <div class="title">Taming LLMs by Scaling Learning Rates with Gradient Grouping</div>
        <div class="authors">Siyuan Li<sup>1,2</sup>, Juanxi Tian<sup>2,4</sup>, Zedong Wang<sup>3</sup>, Xin Jin<sup>2</sup>, Zicheng Liu<sup>1,2</sup>, Wentao Zhang<sup>4</sup>, Dan Xu<sup>3</sup><br>
            <sup>1</sup>Zhejiang University, <sup>2</sup>Westlake University, <sup>3</sup>The Hong Kong University of Science and Technology, <sup>4</sup>Peking University
        </div>
        <div class="buttons">
            <a href="https://arxiv.org/pdf/2506.01049" id="paper-btn" target="_blank">
                <i class="fas fa-file-pdf"></i> Paper
            </a>
            <a href="https://github.com/ScalingOpt/SGG" id="code-btn" target="_blank">
                <i class="fab fa-github"></i> Code
            </a>
        </div>
        <div class="content">
            <h2>Abstract</h2>
            <p>Training large language models (LLMs) poses challenges due to their massive scale and heterogeneous architectures. While adaptive optimizers like AdamW help address gradient variations, they still struggle with efficient and effective parameter-wise learning rate estimation, resulting in training instability, slow convergence, and poor compatibility with parameter-efficient fine-tuning (PEFT) techniques. This work introduces Scaling with Gradient Grouping (SGG), an optimizer wrapper that improves adaptive learning rate estimation by dynamic grouping and group-specific scaling. SGG first groups gradient statistics in each layer into clusters and then applies cluster-specific scaling to calibrate learning rates for each parameter, thus imposing collective group-wise constraints while maintaining precise per-parameter adaptation. Experiments on diverse (M)LLM benchmarks show that SGG integrates seamlessly with existing optimizers, and offers consistent gains and faster convergence over baselines, with various model sizes. Its stability across varying batch sizes and learning rates establishes SGG as a robust choice for LLM optimization.</p>
            <h2>Introduction</h2>
            <p>Optimization algorithms have long been the cornerstone of deep learning systems. Among these, adaptive optimizers stand out for their ability to adjust individual learning rates for each parameter, enabling effective training of large language models (LLMs) with heterogeneous architecture. Yet, their reliance on per-parameter statistics (e.g., first and second moments of gradient) incurs substantial memory overhead, which limits their application, especially in resource-constrained scenarios.</p>
            <img src="https://github.com/ScalingOpt/SGG/raw/main/SGG_1.png" alt="SGG Illustration">
            <h2>Methodology</h2>
            <p>SGG begins with dynamic grouping as GradCluster(mt<sup>l</sup>, K) in Algorithm 1, which partitions momentum vectors mt<sup>l</sup> within each layer l âˆˆ L into K groups with related indices Ct<sup>l</sup> according to their similarity. To achieve this, online clustering stands out as a straightforward solution, and the choice of specific clustering algorithms is then crucial for both effectiveness and efficiency.</p>
            <img src="https://github.com/ScalingOpt/SGG/raw/main/SGG_2.png" alt="SGG Algorithm">
            <h2>Experiments</h2>
            <p>Experiments demonstrate that SGG consistently delivers performance gains and accelerates convergence across different LLM and MLLM benchmarks, such as pre-training on C4, supervised fine-tuning (SFT) on GLUE, PEFT on commonsense reasoning tasks, and Direct Preference Optimization (DPO). For instance, Adam combined with SGG could surpass recent optimizers on C4 pre-training across diverse model sizes (from 60M to 1B). More importantly, SGG enables low-rank pre-training to match full-rank performance without modifications to the training pipeline, yielding up to 30.4% lower validation perplexity over LoRA baselines.</p>
            <h3>Pre-training on C4</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>60M</th>
                        <th>130M</th>
                        <th>350M</th>
                        <th>1B</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Adam</td>
                        <td>34.06</td>
                        <td>25.08</td>
                        <td>18.80</td>
                        <td>15.56</td>
                    </tr>
                    <tr>
                        <td>Adam+SGG</td>
                        <td>30.31</td>
                        <td>22.18</td>
                        <td>17.28</td>
                        <td>14.30</td>
                    </tr>
                    <tr>
                        <td>LoRA</td>
                        <td>34.99</td>
                        <td>33.92</td>
                        <td>25.58</td>
                        <td>19.21</td>
                    </tr>
                    <tr>
                        <td>LoRA+SGG</td>
                        <td>30.62</td>
                        <td>23.62</td>
                        <td>17.86</td>
                        <td>14.73</td>
                    </tr>
                </tbody>
            </table>
            <h3>Supervised Fine-Tuning (SFT) on GLUE</h3>
            <table>
                <thead>
                    <tr>
                        <th>Task</th>
                        <th>Adam</th>
                        <th>Adam+SGG</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>CoLA</td>
                        <td>62.24</td>
                        <td>63.36</td>
                    </tr>
                    <tr>
                        <td>STS-B</td>
                        <td>90.92</td>
                        <td>91.22</td>
                    </tr>
                    <tr>
                        <td>MRPC</td>
                        <td>91.30</td>
                        <td>92.65</td>
                    </tr>
                    <tr>
                        <td>RTE</td>
                        <td>79.42</td>
                        <td>80.87</td>
                    </tr>
                    <tr>
                        <td>SST-2</td>
                        <td>94.57</td>
                        <td>95.58</td>
                    </tr>
                    <tr>
                        <td>MNLI</td>
                        <td>87.18</td>
                        <td>88.32</td>
                    </tr>
                    <tr>
                        <td>QNLI</td>
                        <td>92.33</td>
                        <td>92.88</td>
                    </tr>
                    <tr>
                        <td>QQP</td>
                        <td>92.28</td>
                        <td>93.32</td>
                    </tr>
                </tbody>
            </table>
            <h3>PEFT on Commonsense Reasoning</h3>
            <table>
                <thead>
                    <tr>
                        <th>Task</th>
                        <th>LoRA</th>
                        <th>LoRA+SGG</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>BoolQ</td>
                        <td>68.9</td>
                        <td>70.3</td>
                    </tr>
                    <tr>
                        <td>PIQA</td>
                        <td>80.7</td>
                        <td>83.6</td>
                    </tr>
                    <tr>
                        <td>SIQA</td>
                        <td>77.4</td>
                        <td>78.8</td>
                    </tr>
                    <tr>
                        <td>WinoGrande</td>
                        <td>78.8</td>
                        <td>80.9</td>
                    </tr>
                    <tr>
                        <td>ARC-E</td>
                        <td>77.8</td>
                        <td>81.5</td>
                    </tr>
                    <tr>
                        <td>OBQA</td>
                        <td>74.8</td>
                        <td>79.0</td>
                    </tr>
                </tbody>
            </table>
            <h3>Direct Preference Optimization (DPO)</h3>
            <table>
                <thead>
                    <tr>
                        <th>Optimizer</th>
                        <th>Full-Rank</th>
                        <th>LoRA</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>AdamW</td>
                        <td>71.39</td>
                        <td>70.22</td>
                    </tr>
                    <tr>
                        <td>AdamW+SGG</td>
                        <td>71.85</td>
                        <td>72.02</td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>
    <div class="footer">
        <p>&copy; 2025 Siyuan Li, Juanxi Tian, Zedong Wang, Xin Jin, Zicheng Liu, Wentao Zhang, Dan Xu</p>
    </div>
</body>
</html>